services:
  ollama:
    image: "ollama/ollama"
    ports:
      - "11434:11434"
    volumes:
      - ./.dockerTemps/ML:/root/.ollama/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all # Or specify a specific GPU ID
              capabilities: [gpu]
    networks:
      - ai
  redis:
    build:
      context: ./Redis
      dockerfile: Dockerfile
    ports:
      - "6379:6379"
    volumes:
      - ./.dockerTemps/DB:/data/
    networks:
      - db
  ragdemo:
    build:
      context: .
      dockerfile: RAGDemo/Dockerfile
    ports:
      - "5000:8080"
      - "5002:8081"
    environment:
      - ASPNETCORE_ENVIRONMENT=Development
    networks:
      - api
      - ai
      - db
  ui:
    build:
      context: ./UI
      dockerfile: Dockerfile
    ports:
      - "5001:80"
    networks:
      - api
networks:
  ai:
  api:
  db:
